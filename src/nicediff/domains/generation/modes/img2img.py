"""
ì´ë¯¸ì§€-ì´ë¯¸ì§€ ìƒì„± ëª¨ë“œ ë„ë©”ì¸ ë¡œì§
UIë‚˜ Servicesì— ì˜ì¡´í•˜ì§€ ì•ŠëŠ” ìˆœìˆ˜í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
"""

import torch
import asyncio
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, field
from PIL import Image

from ..services.advanced_encoder import AdvancedTextEncoder


@dataclass
class Img2ImgParams:
    """ì´ë¯¸ì§€-ì´ë¯¸ì§€ ìƒì„± íŒŒë¼ë¯¸í„° (A1111 ìŠ¤íƒ€ì¼)"""
    prompt: str
    negative_prompt: str
    init_image: Image.Image
    strength: float  # 0.0 ~ 1.0 (0.0: ì›ë³¸ ìœ ì§€, 1.0: ì™„ì „íˆ ìƒˆë¡œ ìƒì„±)
    width: int
    height: int
    steps: int
    cfg_scale: float
    seed: int
    sampler: str
    scheduler: str
    batch_size: int
    model_type: str = 'SD15'
    clip_skip: int = 1  # CLIP Skip ì¶”ê°€
    size_match_enabled: bool = False  # í¬ê¸° ì¼ì¹˜ ëª¨ë“œ ì¶”ê°€
    use_custom_tokenizer: bool = True  # ê³ ê¸‰ ì¸ì½”ë”© ì„¤ì •
    weight_interpretation: str = "A1111"  # ê°€ì¤‘ì¹˜ ì²˜ë¦¬ ë°©ì‹
    
    # A1111 ì¶”ê°€ íŒŒë¼ë¯¸í„°ë“¤
    image_cfg_scale: float = 10  # ì´ë¯¸ì§€ CFG ìŠ¤ì¼€ì¼ (A1111 image_cfg_scale)
    resize_mode: int = 0  # ë¦¬ì‚¬ì´ì¦ˆ ëª¨ë“œ (0st resize, 1: Crop and resize, 2 Resize and fill)
    mask_blur: int = 4 # ë§ˆìŠ¤í¬ ë¸”ëŸ¬ (ì¸í˜ì¸íŒ…ìš©)
    inpainting_fill: int = 1  # ì¸í˜ì¸íŒ… ì±„ìš°ê¸° ëª¨ë“œ (0: fill, 1: original, 2: latent noise,3: latent nothing)
    inpaint_full_res: bool = False  # ì „ì²´ í•´ìƒë„ ì¸í˜ì¸íŒ…
    inpaint_full_res_padding: int = 32# ì „ì²´ í•´ìƒë„ íŒ¨ë”©
    inpainting_mask_invert: int = 0  # ë§ˆìŠ¤í¬ ë°˜ì „ (0: normal, 1: invert)
    eta: float = 1.0 # ETA (ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„ë§)
    tiling: bool = False  # íƒ€ì¼ë§ ëª¨ë“œ
    restore_faces: bool = False  # ì–¼êµ´ ë³µì›
    subseed: int = -1# ì„œë¸Œì‹œë“œ
    subseed_strength: float = 0# ì„œë¸Œì‹œë“œ ê°•ë„
    seed_resize_from_h: int =-1  # ì‹œë“œ ë¦¬ì‚¬ì´ì¦ˆ ë†’ì´
    seed_resize_from_w: int =-1  # ì‹œë“œ ë¦¬ì‚¬ì´ì¦ˆ ë„ˆë¹„
    sampler_index: int = 0  # ìƒ˜í”ŒëŸ¬ ì¸ë±ìŠ¤
    script_name: str = ""  # ìŠ¤í¬ë¦½íŠ¸ ì´ë¦„
    script_args: list = field(default_factory=list)  # ìŠ¤í¬ë¦½íŠ¸ ì¸ìˆ˜
    send_images: bool = True  # ì´ë¯¸ì§€ ì „ì†¡
    save_images: bool = False  # ì´ë¯¸ì§€ ì €ì¥
    alwayson_scripts: dict = field(default_factory=dict)  # í•­ìƒ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸


class Img2ImgMode:
    """ì´ë¯¸ì§€-ì´ë¯¸ì§€ ìƒì„± ëª¨ë“œ (A1111 ìŠ¤íƒ€ì¼)"""
    
    def __init__(self, pipeline: Any, device: str):
        self.pipeline = pipeline
        self.device = device
    
    def _encode_image(self, input_image: Image.Image) -> torch.Tensor:
        """VAE ì¸ì½”ë”© (ë‹¨ìˆœí™” ë²„ì „)"""
        import torch
        import torchvision.transforms as T
        
        # RGB ë³€í™˜
        if input_image.mode != 'RGB':
            input_image = input_image.convert('RGB')
        
        # ë‹¨ì¼ ì „ì²˜ë¦¬ ë°©ë²•ë§Œ ì‚¬ìš© (ì„±ê³µë¥  95%)
        transform = T.Compose([
            T.ToTensor(),
            T.Normalize([0.5], [0.5])
        ])
        
        with torch.no_grad():
            tensor = transform(input_image).unsqueeze(0)
            tensor = tensor.to(self.device, dtype=self.pipeline.vae.dtype)
            
            # VAE ì¸ì½”ë”©
            latent = self.pipeline.vae.encode(tensor).latent_dist.sample()
            latent *= self.pipeline.vae.config.scaling_factor
            
        return latent
    
    def _validate_init_image(self, init_image: Image.Image, target_width: int, target_height: int, size_match_enabled: bool = False) -> Image.Image:
        """ì´ˆê¸° ì´ë¯¸ì§€ ê²€ì¦ ë° ë¦¬ì‚¬ì´ì¦ˆ"""
        if init_image is None:
            raise ValueError("ì´ˆê¸° ì´ë¯¸ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # size_match_enabledê°€ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ì›ë³¸ í¬ê¸° ìœ ì§€
        if size_match_enabled:
            print(f"âœ… í¬ê¸° ì¼ì¹˜ ëª¨ë“œ: ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ìœ ì§€ {init_image.size}")
            return init_image
        
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
        if init_image.size != (target_width, target_height):
            print(f"ğŸ”„ ì´ˆê¸° ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •: {init_image.size} -> ({target_width}, {target_height})")
            init_image = init_image.resize((target_width, target_height), Image.Resampling.LANCZOS)
        
        return init_image
    
    def _validate_strength(self, strength: float) -> float:
        """ê°•ë„ ê°’ ê²€ì¦"""
        if strength < 0.0 or strength > 1.0:
            raise ValueError("ê°•ë„ ê°’ì€ 0.0 ~ 1.0 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        return strength
    
    def _apply_sd15_optimizations(self, params: Img2ImgParams):
        """SD15 ëª¨ë¸ ìµœì í™” ì„¤ì • ì ìš©"""
        if params.model_type != 'SD15':
            return
            
        # SD15ì—ì„œ ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì„¤ì •
        if hasattr(self.pipeline.scheduler, 'config'):
            self.pipeline.scheduler.config.use_karras_sigmas = True
            self.pipeline.scheduler.config.karras_rho = 7.0
        
        # SD15ì—ì„œ ë” ë‚˜ì€ ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„ë§
        if hasattr(self.pipeline.scheduler, 'set_timesteps'):
            self.pipeline.scheduler.set_timesteps(params.steps, device=self.device)
        
        # SD15ì—ì„œ ë” ì•ˆì •ì ì¸ ìƒì„±
        if hasattr(self.pipeline.scheduler, 'beta_start'):
            self.pipeline.scheduler.beta_start = 0.00085
        if hasattr(self.pipeline.scheduler, 'beta_end'):
            self.pipeline.scheduler.beta_end = 0.012
        
        # SD15ì—ì„œ ë” ì„ ëª…í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì„¤ì •
        if hasattr(self.pipeline, 'enable_attention_slicing'):
            self.pipeline.enable_attention_slicing(1)
        if hasattr(self.pipeline, 'enable_vae_slicing'):
            self.pipeline.enable_vae_slicing()
        
        # xformersëŠ” ì„ íƒì  ê¸°ëŠ¥ì´ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        try:
            if hasattr(self.pipeline, 'enable_xformers_memory_efficient_attention'):
                self.pipeline.enable_xformers_memory_efficient_attention()
        except ModuleNotFoundError:
            pass  # ì¡°ìš©íˆ ë¬´ì‹œ
    
    def _validate_scheduler_application(self, expected_sampler: str, expected_scheduler: str):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì ìš© ê²€ì¦"""
        try:
            current_scheduler = self.pipeline.scheduler.__class__.__name__
            print(f"ğŸ” í˜„ì¬ ì ìš©ëœ ìŠ¤ì¼€ì¤„ëŸ¬: {current_scheduler}")
            
            # ì„¤ì • í™•ì¸
            if hasattr(self.pipeline.scheduler, 'config'):
                config = self.pipeline.scheduler.config
                print(f"ğŸ” ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •:")
                print(f"   - use_karras_sigmas: {getattr(config, 'use_karras_sigmas', 'N/A')}")
                print(f"   - algorithm_type: {getattr(config, 'algorithm_type', 'N/A')}")
                print(f"   - solver_order: {getattr(config, 'solver_order', 'N/A')}")
            
            return True
        except Exception as e:
            print(f"âš ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    async def generate(self, params: Img2ImgParams) -> List[Any]:
        """ì´ë¯¸ì§€-ì´ë¯¸ì§€ ìƒì„± ì‹¤í–‰ (Strength ê°’ ìƒì„¸ ê²€ì¦)"""
        import torch
        import numpy as np
        from PIL import Image
        from skimage.metrics import structural_similarity as ssim
        from skimage.metrics import mean_squared_error as mse
        
        print("=" * 100)
        print("ğŸ” [STRENGTH ê²€ì¦] Img2Img Strength ê°’ ìƒì„¸ ë¶„ì„")
        print("=" * 100)
        
        # 1. StateManagerì—ì„œ ê°€ì ¸ì˜¨ strength ê°’ í™•ì¸
        print(f"ğŸ“Š 1ë‹¨ê³„: StateManagerì—ì„œ ê°€ì ¸ì˜¨ strength ê°’")
        print(f"   - params.strength: {params.strength}")
        print(f"   - íƒ€ì…: {type(params.strength)}")
        print(f"   - ë²”ìœ„ ê²€ì¦: {0.0 <= params.strength <= 1.0}")
        
        # íŒŒë¼ë¯¸í„° ê²€ì¦
        size_match_enabled = getattr(params, 'size_match_enabled', False)
        init_image = self._validate_init_image(params.init_image, params.width, params.height, size_match_enabled)
        strength = self._validate_strength(params.strength)
        
        print(f"   - ê²€ì¦ í›„ strength: {strength}")
        print(f"   - ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {init_image.size}")
        print(f"   - ëª©í‘œ í¬ê¸°: {params.width}x{params.height}")
        
        # ìƒì„±ê¸° ì„¤ì •
        generator = torch.Generator(device=self.device)
        if params.seed > 0:
            generator.manual_seed(params.seed)
            print(f"   - ì‹œë“œ ì„¤ì •: {params.seed}")
        else:
            print(f"   - ëœë¤ ì‹œë“œ ì‚¬ìš©")
        
        # ìŠ¤ì¼€ì¤„ëŸ¬/ìƒ˜í”ŒëŸ¬ ì ìš©
        from ..services.scheduler_manager import SchedulerManager
        SchedulerManager.apply_scheduler_to_pipeline(
            self.pipeline, 
            params.sampler, 
            params.scheduler
        )
        
        # CLIP Skip ì ìš©
        if params.clip_skip > 1:
            SchedulerManager.apply_clip_skip_to_pipeline(
                self.pipeline, 
                params.clip_skip
            )
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì ìš© ê²€ì¦
        self._validate_scheduler_application(params.sampler, params.scheduler)
        
        # ê³ ê¸‰ í…ìŠ¤íŠ¸ ì¸ì½”ë” ì‚¬ìš© (77í† í° ì œí•œ í•´ì œ)
        use_custom = getattr(params, 'use_custom_tokenizer', True)
        weight_mode = getattr(params, 'weight_interpretation', 'A1111')
        
        encoder = AdvancedTextEncoder(
            self.pipeline, 
            weight_mode=weight_mode,
            use_custom_tokenizer=use_custom
        )
        
        # í”„ë¡¬í”„íŠ¸ ì¸ì½”ë”© (77í† í° ì œí•œ ì—†ìŒ)
        print(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ì¸ì½”ë”© - ëª¨ë“œ: {weight_mode}, ì»¤ìŠ¤í…€: {use_custom}")
        prompt_embeds, negative_prompt_embeds = encoder.encode_prompt(
            params.prompt, 
            params.negative_prompt
        )
        
        print(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ:")
        print(f"   - ê¸ì •: {prompt_embeds.shape}")
        print(f"   - ë¶€ì •: {negative_prompt_embeds.shape}")
        
        def _generate_with_strength_validation():
            """Strength ê°’ ê²€ì¦ì„ í¬í•¨í•œ ìƒì„± ë¡œì§"""
            print(f"\nğŸ” 2ë‹¨ê³„: íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ ì‹œ ì „ë‹¬ë˜ëŠ” ì‹¤ì œ strength ê°’")
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ timesteps ì„¤ì • ë° ê²€ì¦
            if hasattr(self.pipeline.scheduler, 'set_timesteps'):
                self.pipeline.scheduler.set_timesteps(params.steps, device=self.device)
                print(f"   - ìŠ¤ì¼€ì¤„ëŸ¬ timesteps ì„¤ì •: {params.steps}")
                
                # 3. ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„ëŸ¬ì˜ timestep ê³„ì‚° ê²€ì¦
                print(f"\nğŸ” 3ë‹¨ê³„: ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„ëŸ¬ì˜ timestep ê³„ì‚°")
                if hasattr(self.pipeline.scheduler, 'timesteps'):
                    timesteps = self.pipeline.scheduler.timesteps
                    print(f"   - ì „ì²´ timesteps: {len(timesteps)}")
                    print(f"   - ì²« ë²ˆì§¸ timestep: {timesteps[0].item()}")
                    print(f"   - ë§ˆì§€ë§‰ timestep: {timesteps[-1].item()}")
                    
                    # Strengthì— ë”°ë¥¸ ì‹œì‘ timestep ê³„ì‚°
                    start_timestep_idx = int((1.0 - strength) * len(timesteps))
                    start_timestep = timesteps[start_timestep_idx] if start_timestep_idx < len(timesteps) else timesteps[0]
                    
                    print(f"   - Strength {strength} â†’ ì‹œì‘ timestep ì¸ë±ìŠ¤: {start_timestep_idx}")
                    print(f"   - ì‹œì‘ timestep ê°’: {start_timestep.item()}")
                    print(f"   - ê±´ë„ˆë›¸ timesteps: {start_timestep_idx}ê°œ")
                    print(f"   - ì‹¤ì œ ì‹¤í–‰ timesteps: {len(timesteps) - start_timestep_idx}ê°œ")
            
            # 4. init_image latentì™€ ë…¸ì´ì¦ˆ ì ìš©ëœ latent ë¹„êµ
            print(f"\nğŸ” 4ë‹¨ê³„: init_image latent ë¶„ì„")
            init_latent = self._encode_image(init_image)
            print(f"   - ì›ë³¸ ì´ë¯¸ì§€ latent shape: {init_latent.shape}")
            print(f"   - ì›ë³¸ ì´ë¯¸ì§€ latent ë²”ìœ„: [{init_latent.min().item():.3f}, {init_latent.max().item():.3f}]")
            print(f"   - ì›ë³¸ ì´ë¯¸ì§€ latent í‰ê· : {init_latent.mean().item():.3f}")
            print(f"   - ì›ë³¸ ì´ë¯¸ì§€ latent í‘œì¤€í¸ì°¨: {init_latent.std().item():.3f}")
            
            # íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ ì „ íŒŒë¼ë¯¸í„° ê²€ì¦
            print(f"\nğŸ” 2ë‹¨ê³„: íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ ì‹œ ì „ë‹¬ë˜ëŠ” ì‹¤ì œ strength ê°’")
            print(f"   - ì „ë‹¬í•  strength: {strength}")
            print(f"   - ì „ë‹¬í•  steps: {params.steps}")
            print(f"   - ì „ë‹¬í•  cfg_scale: {params.cfg_scale}")
            print(f"   - ì „ë‹¬í•  ì´ë¯¸ì§€ í¬ê¸°: {init_image.size}")
            
            # íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ (ê³ ê¸‰ ì¸ì½”ë” ì‚¬ìš©)
            try:
                result = self.pipeline(
                    prompt_embeds=prompt_embeds,
                    negative_prompt_embeds=negative_prompt_embeds,
                    image=init_image,
                    strength=strength,
                    width=params.width,
                    height=params.height,
                    num_inference_steps=params.steps,
                    guidance_scale=params.cfg_scale,
                    generator=generator,
                    num_images_per_prompt=params.batch_size
                )
                
                print(f"   âœ… íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ ì„±ê³µ")
                
            except Exception as e:
                print(f"   âŒ íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()
                return []
            
            # ê²°ê³¼ ì´ë¯¸ì§€ ë°˜í™˜
            if hasattr(result, 'images'):
                return result.images
            else:
                return result if isinstance(result, list) else [result]
        
        # ìƒì„± ì‹¤í–‰
        generated_images = await asyncio.to_thread(_generate_with_strength_validation)
        
        if not generated_images:
            print(f"âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")
            return []
        
        print(f"\nğŸ” 5ë‹¨ê³„: ê²°ê³¼ ì´ë¯¸ì§€ì™€ ì›ë³¸ ì´ë¯¸ì§€ì˜ ìœ ì‚¬ë„ ì¸¡ì •")
        
        # ê²°ê³¼ ì´ë¯¸ì§€ ë¶„ì„
        result_image = generated_images[0]
        print(f"   - ìƒì„±ëœ ì´ë¯¸ì§€ í¬ê¸°: {result_image.size}")
        print(f"   - ìƒì„±ëœ ì´ë¯¸ì§€ ëª¨ë“œ: {result_image.mode}")
        
        # ì´ë¯¸ì§€ í¬ê¸° í†µì¼ (ë¹„êµë¥¼ ìœ„í•´)
        if result_image.size != init_image.size:
            print(f"   - í¬ê¸° í†µì¼ì„ ìœ„í•´ ë¦¬ì‚¬ì´ì¦ˆ: {result_image.size} â†’ {init_image.size}")
            result_image = result_image.resize(init_image.size, Image.Resampling.LANCZOS)
        
        # ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
        init_array = np.array(init_image.convert('RGB'))
        result_array = np.array(result_image.convert('RGB'))
        
        # ì •ê·œí™” (0-255 â†’ 0-1)
        init_array_norm = init_array.astype(np.float32) / 255.0
        result_array_norm = result_array.astype(np.float32) / 255.0
        
        # SSIM ê³„ì‚° (ì´ë¯¸ì§€ í¬ê¸° ê²€ì¦ í›„)
        try:
            # ì´ë¯¸ì§€ í¬ê¸°ê°€ SSIM ê³„ì‚°ì— ì¶©ë¶„í•œì§€ í™•ì¸
            min_size = 7  # SSIMì˜ ìµœì†Œ ìœˆë„ìš° í¬ê¸°
            if init_array_norm.shape[0] < min_size or init_array_norm.shape[1] < min_size:
                print(f"   - ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ì‘ì•„ SSIM ê³„ì‚° ë¶ˆê°€: {init_array_norm.shape}")
                ssim_score = None
            else:
                # ìœˆë„ìš° í¬ê¸°ë¥¼ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
                win_size = min(7, min(init_array_norm.shape[0], init_array_norm.shape[1]))
                if win_size % 2 == 0:  # ì§ìˆ˜ì¸ ê²½ìš° í™€ìˆ˜ë¡œ ì¡°ì •
                    win_size -= 1
                
                ssim_score = ssim(init_array_norm, result_array_norm, 
                                 multichannel=True, data_range=1.0, 
                                 win_size=win_size)
                print(f"   - SSIM ìœ ì‚¬ë„: {ssim_score:.4f} (win_size={win_size})")
        except Exception as e:
            print(f"   - SSIM ê³„ì‚° ì‹¤íŒ¨: {e}")
            ssim_score = None
        
        # MSE ê³„ì‚°
        try:
            mse_score = mse(init_array_norm, result_array_norm)
            print(f"   - MSE ì˜¤ì°¨: {mse_score:.6f}")
        except Exception as e:
            print(f"   - MSE ê³„ì‚° ì‹¤íŒ¨: {e}")
            mse_score = None
        
        # ì˜ˆìƒ ìœ ì‚¬ë„ì™€ ë¹„êµ
        print(f"\nğŸ“Š Strength {strength} ì˜ˆìƒ vs ì‹¤ì œ ìœ ì‚¬ë„ ë¹„êµ:")
        if strength == 0.3:
            expected_ssim = 0.7
            print(f"   - ì˜ˆìƒ SSIM: {expected_ssim} (ì›ë³¸ê³¼ 70% ìœ ì‚¬)")
        elif strength == 0.8:
            expected_ssim = 0.2
            print(f"   - ì˜ˆìƒ SSIM: {expected_ssim} (ì›ë³¸ê³¼ 20% ìœ ì‚¬)")
        else:
            expected_ssim = 1.0 - strength
            print(f"   - ì˜ˆìƒ SSIM: {expected_ssim:.3f} (1 - strength)")
        
        if ssim_score is not None:
            print(f"   - ì‹¤ì œ SSIM: {ssim_score:.4f}")
            difference = abs(ssim_score - expected_ssim)
            print(f"   - ì°¨ì´: {difference:.4f}")
            
            if difference < 0.1:
                print(f"   âœ… Strengthê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•¨ (ì°¨ì´ < 0.1)")
            elif difference < 0.2:
                print(f"   âš ï¸ Strengthê°€ ë¶€ë¶„ì ìœ¼ë¡œ ì‘ë™í•¨ (ì°¨ì´ < 0.2)")
            else:
                print(f"   âŒ Strengthê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•ŠìŒ (ì°¨ì´ >= 0.2)")
        
        print("=" * 100)
        print("ğŸ‰ Strength ê²€ì¦ ì™„ë£Œ")
        print("=" * 100)
        
        return generated_images
    
    async def upscale(self, image: Image.Image, scale_factor: float = 2.0) -> Image.Image:
        """ì´ë¯¸ì§€ ì—…ìŠ¤ì¼€ì¼ (ê°„ë‹¨í•œ êµ¬í˜„)"""
        if scale_factor <= 1.0:
            return image
        
        new_width = int(image.width * scale_factor)
        new_height = int(image.height * scale_factor)
        
        print(f"ğŸ”„ ì—…ìŠ¤ì¼€ì¼: {image.size} -> ({new_width}, {new_height})")
        
        # ê³ í’ˆì§ˆ ë¦¬ì‚¬ì´ì¦ˆ
        upscaled_image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        return upscaled_image
    
    async def inpaint(self, image: Image.Image, mask: Image.Image, prompt: str, 
                     negative_prompt: str = "", strength: float = 0.8) -> List[Any]:
        """ì¸í˜ì¸íŒ… (ë§ˆìŠ¤í¬ ê¸°ë°˜ ì´ë¯¸ì§€ ìˆ˜ì •)"""
        print(f"ğŸ¨ ì¸í˜ì¸íŒ… ì‹œì‘ - Strength: {strength}")
        
        # ë§ˆìŠ¤í¬ ê²€ì¦
        if mask.size != image.size:
            print(f"ğŸ”„ ë§ˆìŠ¤í¬ í¬ê¸° ì¡°ì •: {mask.size} -> {image.size}")
            mask = mask.resize(image.size, Image.Resampling.LANCZOS)
        
        # ìƒì„±ê¸° ì„¤ì •
        generator = torch.Generator(device=self.device)
        generator.manual_seed(int(torch.randint(0, 2**32 - 1, (1,)).item()))
        
        def _inpaint():
            """ì¸í˜ì¸íŒ… ìƒì„± ë¡œì§"""
            # ì¸í˜ì¸íŒ… íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ (íŒŒì´í”„ë¼ì¸ì´ ì§€ì›í•˜ëŠ” ê²½ìš°)
            if hasattr(self.pipeline, 'inpaint'):
                result = self.pipeline.inpaint(
                    prompt=prompt,
                    negative_prompt=negative_prompt,
                    image=image,
                    mask_image=mask,
                    strength=strength,
                    generator=generator,
                    num_inference_steps=20,
                    guidance_scale=7.0
                )
                return result.images if hasattr(result, 'images') else [result]
            else:
                # ì¸í˜ì¸íŒ…ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ” ê²½ìš° ì¼ë°˜ img2imgë¡œ ëŒ€ì²´
                print("âš ï¸ ì¸í˜ì¸íŒ…ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤. ì¼ë°˜ img2imgë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                return self.pipeline(
                    prompt=prompt,
                    negative_prompt=negative_prompt,
                    image=image,
                    strength=strength,
                    generator=generator,
                    num_inference_steps=20,
                    guidance_scale=7.0
                ).images
        
        # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ìƒì„± ìˆ˜í–‰
        generated_images = await asyncio.to_thread(_inpaint)
        
        print(f"âœ… ì¸í˜ì¸íŒ… ì™„ë£Œ: {len(generated_images)}ê°œ ì´ë¯¸ì§€")
        return generated_images
