#!/usr/bin/env python3

import torch
from diffusers.pipelines.stable_diffusion_xl.pipeline_stable_diffusion_xl import StableDiffusionXLPipeline

def test_sdxl_loading():
    print("=== SDXL ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸ ===")
    
    try:
        print("ğŸ”„ SDXL ëª¨ë¸ ë¡œë”© ì¤‘ (diffusers ë‚´ì¥ ëª¨ë¸ ì‚¬ìš©)...")
        print("âš ï¸ ì´ ì‘ì—…ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤...")
        
        # diffusers ë‚´ì¥ SDXL ëª¨ë¸ ì‚¬ìš©
        pipeline = StableDiffusionXLPipeline.from_pretrained(
            "stabilityai/stable-diffusion-xl-base-1.0",
            torch_dtype=torch.float16,
            variant="fp16",
            use_safetensors=True
        )
        
        print("âœ… SDXL íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì™„ë£Œ")
        
        # í† í¬ë‚˜ì´ì € í™•ì¸
        print("\nğŸ“‹ í† í¬ë‚˜ì´ì € í™•ì¸:")
        print(f"  tokenizer ì¡´ì¬: {hasattr(pipeline, 'tokenizer')}")
        print(f"  tokenizer_2 ì¡´ì¬: {hasattr(pipeline, 'tokenizer_2')}")
        
        if hasattr(pipeline, 'tokenizer') and pipeline.tokenizer is not None:
            print(f"  tokenizer íƒ€ì…: {type(pipeline.tokenizer)}")
            print(f"  tokenizer ëª¨ë¸ ìµœëŒ€ ê¸¸ì´: {pipeline.tokenizer.model_max_length}")
            print(f"  tokenizer ì–´íœ˜ í¬ê¸°: {pipeline.tokenizer.vocab_size}")
        
        if hasattr(pipeline, 'tokenizer_2') and pipeline.tokenizer_2 is not None:
            print(f"  tokenizer_2 íƒ€ì…: {type(pipeline.tokenizer_2)}")
            print(f"  tokenizer_2 ëª¨ë¸ ìµœëŒ€ ê¸¸ì´: {pipeline.tokenizer_2.model_max_length}")
            print(f"  tokenizer_2 ì–´íœ˜ í¬ê¸°: {pipeline.tokenizer_2.vocab_size}")
        
        # í…ìŠ¤íŠ¸ ì¸ì½”ë” í™•ì¸
        print("\nğŸ“‹ í…ìŠ¤íŠ¸ ì¸ì½”ë” í™•ì¸:")
        print(f"  text_encoder ì¡´ì¬: {hasattr(pipeline, 'text_encoder')}")
        print(f"  text_encoder_2 ì¡´ì¬: {hasattr(pipeline, 'text_encoder_2')}")
        
        if hasattr(pipeline, 'text_encoder') and pipeline.text_encoder is not None:
            print(f"  text_encoder íƒ€ì…: {type(pipeline.text_encoder)}")
        
        if hasattr(pipeline, 'text_encoder_2') and pipeline.text_encoder_2 is not None:
            print(f"  text_encoder_2 íƒ€ì…: {type(pipeline.text_encoder_2)}")
        
        # í† í¬ë‚˜ì´ì € ì°¨ì´ì  í…ŒìŠ¤íŠ¸
        if hasattr(pipeline, 'tokenizer') and hasattr(pipeline, 'tokenizer_2'):
            test_prompt = "a beautiful landscape"
            print(f"\nğŸ§ª í† í¬ë‚˜ì´ì € ì°¨ì´ì  í…ŒìŠ¤íŠ¸:")
            print(f"  í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸: '{test_prompt}'")
            
            # ì²« ë²ˆì§¸ í† í¬ë‚˜ì´ì €ë¡œ í† í°í™”
            tokens1 = pipeline.tokenizer(test_prompt, return_tensors="pt")
            print(f"  tokenizer í† í° ìˆ˜: {tokens1.input_ids.shape[1]}")
            
            # ë‘ ë²ˆì§¸ í† í¬ë‚˜ì´ì €ë¡œ í† í°í™”
            tokens2 = pipeline.tokenizer_2(test_prompt, return_tensors="pt")
            print(f"  tokenizer_2 í† í° ìˆ˜: {tokens2.input_ids.shape[1]}")
            
            # í† í° ID ë¹„êµ
            print(f"  í† í° IDê°€ ë‹¤ë¥¸ê°€?: {not torch.equal(tokens1.input_ids, tokens2.input_ids)}")
            
            # í† í° ID ìƒì„¸ ë¹„êµ
            print(f"  tokenizer í† í° ID: {tokens1.input_ids[0].tolist()}")
            print(f"  tokenizer_2 í† í° ID: {tokens2.input_ids[0].tolist()}")
        
        print("\nâœ… SDXL ë‘ í† í¬ë‚˜ì´ì € ì„¤ì • í™•ì¸ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ SDXL ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_sdxl_loading() 