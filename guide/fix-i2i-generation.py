# state_manager.pyì˜ start_generation ë©”ì„œë“œ ìˆ˜ì •

async def start_generation(self):
    """ì´ë¯¸ì§€ ìƒì„± ì‹œì‘ (ìˆ˜ì •ëœ ë²„ì „)"""
    if self.get('is_generating'):
        self._notify_user('ì´ë¯¸ ìƒì„± ì¤‘ì…ë‹ˆë‹¤.', 'warning')
        return
    
    if not self.model_loader.get_current_pipeline():
        self._notify_user('ëª¨ë¸ì„ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.', 'warning')
        return
    
    self.stop_generation_flag.clear()
    self.set('is_generating', True)
    
    try:
        # ë„ë©”ì¸ ì „ëµ ì‚¬ìš©
        pipeline = self.model_loader.get_current_pipeline()
        strategy = BasicGenerationStrategy(pipeline, self.device, state=self)
        
        # íŒŒë¼ë¯¸í„° ì¤€ë¹„
        params = self.get('current_params')
        params_dict = {
            'prompt': params.prompt,
            'negative_prompt': params.negative_prompt,
            'width': params.width,
            'height': params.height,
            'steps': params.steps,
            'cfg_scale': params.cfg_scale,
            'seed': params.seed,
            'sampler': params.sampler,
            'scheduler': params.scheduler,
            'batch_size': params.batch_size,
            'clip_skip': getattr(params, 'clip_skip', 1),
            'vae': self.get('current_vae_path'),
            'loras': self.get('current_loras')
        }
        
        # í˜„ì¬ ëª¨ë“œ í™•ì¸
        current_mode = self.get('current_mode', 'txt2img')
        
        # i2i ëª¨ë“œ ì²˜ë¦¬
        if current_mode in ['img2img', 'inpaint', 'upscale']:
            params_dict['img2img_mode'] = True
            
            # strength ê°’ ì¶”ê°€ (ì¤‘ìš”!)
            strength = getattr(params, 'strength', 0.8)
            params_dict['strength'] = strength
            print(f"ğŸ”§ i2i Strength ê°’: {strength}")
            
            # init_image ì¶”ê°€ (ì¤‘ìš”!)
            init_image = self.get('init_image')
            if init_image is None:
                # uploaded_imageì—ì„œ ê°€ì ¸ì˜¤ê¸° ì‹œë„
                uploaded_image = self.get('uploaded_image')
                if uploaded_image is not None:
                    # numpy to PIL
                    from PIL import Image
                    import numpy as np
                    if isinstance(uploaded_image, np.ndarray):
                        init_image = Image.fromarray(uploaded_image.astype('uint8'))
                        self.set('init_image', init_image)  # ì €ì¥
                    
            params_dict['init_image'] = init_image
            
            # ë””ë²„ê·¸ ì¶œë ¥
            print(f"ğŸ” i2i ëª¨ë“œ íŒŒë¼ë¯¸í„°:")
            print(f"  - init_image: {init_image}")
            print(f"  - strength: {strength}")
            print(f"  - size: {params.width}x{params.height}")
            
            if init_image is None:
                self._notify_user('ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.', 'warning')
                self.set('is_generating', False)
                return
        
        # ëª¨ë¸ ì •ë³´
        model_info = self.get('current_model_info', {})
        
        # ìƒì„± ì‹œì‘ ì´ë²¤íŠ¸
        self._notify('generation_started', {
            'mode': current_mode,
            'params': params_dict
        })
        
        # ì „ëµ ì‹¤í–‰
        result = await strategy.execute(params_dict, model_info)
        
        if result.success and result.images:
            # ê²°ê³¼ ì²˜ë¦¬
            self.set('last_generated_images', result.images)
            self._notify('image_generated', result.images)
            
            # í›„ì²˜ë¦¬
            await self._post_process_generation(result.images, params_dict)
            
            self._notify_user(f'{len(result.images)}ê°œ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!', 'positive')
        else:
            error_msg = ', '.join(result.errors) if result.errors else 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'
            self._notify_user(f'ìƒì„± ì‹¤íŒ¨: {error_msg}', 'negative')
            
    except Exception as e:
        print(f"âŒ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        self._notify_user(f'ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}', 'negative')
        
    finally:
        self.set('is_generating', False)
        self._notify('generation_completed', {})

# img2img.pyì˜ _encode_image ë©”ì„œë“œ ê°œì„ 

def _encode_image(self, image: Image.Image) -> torch.Tensor:
    """ì´ë¯¸ì§€ë¥¼ latent spaceë¡œ ì¸ì½”ë”© (ê°œì„ ëœ ë²„ì „)"""
    print(f"ğŸ” ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹œì‘: í¬ê¸°={image.size}, ëª¨ë“œ={image.mode}")
    
    # RGBë¡œ ë³€í™˜ (í•„ìˆ˜)
    if image.mode != 'RGB':
        image = image.convert('RGB')
    
    with torch.no_grad():
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ - ë” ì•ˆì „í•œ ë°©ì‹
        try:
            # ë°©ë²• 1: image_processor ì‚¬ìš©
            if hasattr(self.pipeline, 'image_processor') and self.pipeline.image_processor is not None:
                image_tensor = self.pipeline.image_processor.preprocess(image)
            # ë°©ë²• 2: feature_extractor ì‚¬ìš©
            elif hasattr(self.pipeline, 'feature_extractor') and self.pipeline.feature_extractor is not None:
                image_tensor = self.pipeline.feature_extractor(
                    image, 
                    return_tensors="pt"
                ).pixel_values
            # ë°©ë²• 3: ìˆ˜ë™ ì „ì²˜ë¦¬
            else:
                import torchvision.transforms as transforms
                transform = transforms.Compose([
                    transforms.ToTensor(),
                    transforms.Normalize([0.5], [0.5])  # -1 to 1ë¡œ ì •ê·œí™”
                ])
                image_tensor = transform(image).unsqueeze(0)
                
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜, ìˆ˜ë™ ì²˜ë¦¬ë¡œ ëŒ€ì²´: {e}")
            # ìµœí›„ì˜ ìˆ˜ë‹¨: ì§ì ‘ ë³€í™˜
            import numpy as np
            import torch
            np_image = np.array(image).astype(np.float32) / 255.0
            np_image = (np_image - 0.5) / 0.5  # -1 to 1
            image_tensor = torch.from_numpy(np_image).permute(2, 0, 1).unsqueeze(0)
        
        # ë””ë°”ì´ìŠ¤ì™€ ë°ì´í„° íƒ€ì… ë§ì¶”ê¸°
        image_tensor = image_tensor.to(self.device, dtype=self.pipeline.vae.dtype)
        
        # VAE ì¸ì½”ë”©
        latent = self.pipeline.vae.encode(image_tensor).latent_dist.sample()
        latent = latent * self.pipeline.vae.config.scaling_factor
        
        print(f"âœ… ì´ë¯¸ì§€ ì¸ì½”ë”© ì™„ë£Œ: latent shape={latent.shape}, dtype={latent.dtype}")
        return latent

# parameter_panel.pyì— strength ìŠ¬ë¼ì´ë” ì¶”ê°€ í™•ì¸

def render_i2i_controls(self):
    """i2i ëª¨ë“œ ì „ìš© ì»¨íŠ¸ë¡¤ ë Œë”ë§"""
    current_params = self.state.get('current_params')
    
    with ui.card().classes('w-full bg-gray-800 p-3'):
        ui.label('ğŸ¨ Image to Image ì„¤ì •').classes('text-lg font-bold mb-2')
        
        # Strength ìŠ¬ë¼ì´ë” (ì¤‘ìš”!)
        strength_value = getattr(current_params, 'strength', 0.8)
        with ui.row().classes('w-full items-center gap-2'):
            ui.label('Strength:').classes('text-sm')
            self.strength_slider = ui.slider(
                min=0.0, 
                max=1.0, 
                step=0.05,
                value=strength_value
            ).on('update:model-value', 
                 lambda e: self.state.update_param('strength', e.args)
            ).classes('flex-1')
            ui.label(f'{strength_value:.2f}').classes('text-sm w-12 text-right')
        
        # Strength ì„¤ëª…
        ui.label('0.0 = ì›ë³¸ ìœ ì§€, 1.0 = ì™„ì „ ì¬ìƒì„±').classes('text-xs text-gray-400')
        
        # ì´ë¯¸ì§€ ì •ë³´ í‘œì‹œ
        init_image = self.state.get('init_image')
        if init_image:
            with ui.row().classes('w-full mt-2 text-sm'):
                if hasattr(init_image, 'size'):
                    ui.label(f'ğŸ“ í¬ê¸°: {init_image.size[0]}x{init_image.size[1]}')
                ui.label(f'ğŸ“· ëª¨ë“œ: {getattr(init_image, "mode", "Unknown")}')

# ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹œ ìë™ ëª¨ë“œ ì „í™˜ í™•ì¸ (main.py)

@app.post('/api/upload_image')
async def upload_image(file: UploadFile = File(...)):
    """ì´ë¯¸ì§€ ì—…ë¡œë“œ API ì—”ë“œí¬ì¸íŠ¸ (ê°œì„ )"""
    try:
        contents = await file.read()
        image = Image.open(io.BytesIO(contents)).convert('RGB')
        
        # í¬ê¸° ì¡°ì •
        width, height = image.size
        max_size = 1544
        if width > max_size or height > max_size:
            if width > height:
                new_width = max_size
                new_height = int(height * (max_size / width))
            else:
                new_height = max_size
                new_width = int(width * (max_size / height))
            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        # StateManagerì— ì €ì¥
        state_manager.set('init_image', image)  # PIL Image ì €ì¥
        state_manager.set('uploaded_image', np.array(image))  # numpyë„ ì €ì¥
        
        # í˜„ì¬ ëª¨ë“œê°€ txt2imgë©´ ìë™ìœ¼ë¡œ img2imgë¡œ ì „í™˜
        current_mode = state_manager.get('current_mode', 'txt2img')
        if current_mode == 'txt2img':
            state_manager.set('current_mode', 'img2img')
            print("ğŸ”„ ìë™ìœ¼ë¡œ img2img ëª¨ë“œë¡œ ì „í™˜")
        
        # base64 ë°˜í™˜
        buf = io.BytesIO()
        image.save(buf, format='PNG')
        b64 = base64.b64encode(buf.getvalue()).decode('utf-8')
        
        return {
            'success': True,
            'shape': image.size,
            'base64': f'data:image/png;base64,{b64}',
            'filename': file.filename,
            'mode': state_manager.get('current_mode')
        }
        
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {'success': False, 'error': str(e)}