# ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ í†µí•© êµ¬í˜„ ì§€ì¹¨

## ğŸ¯ ëª©í‘œ
**ComfyUI ê³ ê¸‰ ì¸ì½”ë”© + í”„ë¦¬ì…‹ ì‹œìŠ¤í…œ í†µí•©ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ë¥¼ ì™„ì „íˆ ê°œì„ **

## ğŸ“‹ êµ¬í˜„ ë‚´ìš©

### 1. ê³ ê¸‰ í…ìŠ¤íŠ¸ ì¸ì½”ë” êµ¬í˜„ (ComfyUI ê¸°ë°˜)

**íŒŒì¼: src/nicediff/domains/generation/services/advanced_encoder.py**

```python
import torch
import numpy as np
import itertools
from typing import List, Tuple, Dict, Any, Optional
from math import gcd
import re

class AdvancedTextEncoder:
    """ComfyUI ìŠ¤íƒ€ì¼ ê³ ê¸‰ í…ìŠ¤íŠ¸ ì¸ì½”ë”©"""
    
    def __init__(self, pipeline, weight_mode="A1111", use_custom_tokenizer=True):
        self.pipeline = pipeline
        self.weight_mode = weight_mode  # "A1111" ë˜ëŠ” "comfy++"
        self.use_custom_tokenizer = use_custom_tokenizer
        self.tokenizer = pipeline.tokenizer
        self.text_encoder = pipeline.text_encoder
        
    def parse_prompt_weights(self, text: str) -> List[Tuple[str, float, int]]:
        """A1111 ìŠ¤íƒ€ì¼ ê°€ì¤‘ì¹˜ íŒŒì‹±: (word:1.2), ((word)), [word]"""
        
        # ê°€ì¤‘ì¹˜ íŒ¨í„´ ì •ì˜
        patterns = [
            (r'\(\((.*?)\)\)', 1.21),  # ((word)) = 1.21
            (r'\((.*?):([0-9\.]+)\)', None),  # (word:1.2)
            (r'\((.*?)\)', 1.1),  # (word) = 1.1
            (r'\[(.*?)\]', 0.909),  # [word] = 1/1.1
        ]
        
        tokens = []
        word_id = 1
        
        remaining_text = text
        while remaining_text:
            matched = False
            
            # íŒ¨í„´ ë§¤ì¹­ ì‹œë„
            for pattern, default_weight in patterns:
                match = re.search(pattern, remaining_text)
                if match:
                    # ë§¤ì¹­ ì´ì „ í…ìŠ¤íŠ¸ ì²˜ë¦¬
                    before = remaining_text[:match.start()].strip()
                    if before:
                        for word in before.split():
                            tokens.append((word, 1.0, word_id))
                            word_id += 1
                    
                    # ê°€ì¤‘ì¹˜ ì ìš©ëœ ë¶€ë¶„ ì²˜ë¦¬
                    if default_weight is None:  # (word:1.2) í˜•íƒœ
                        word, weight = match.groups()
                        weight = float(weight)
                    else:
                        word = match.group(1)
                        weight = default_weight
                    
                    for w in word.strip().split():
                        tokens.append((w, weight, word_id))
                        word_id += 1
                    
                    # ë§¤ì¹­ëœ ë¶€ë¶„ ì œê±°
                    remaining_text = remaining_text[match.end():].strip()
                    matched = True
                    break
            
            if not matched:
                # íŒ¨í„´ì´ ì—†ìœ¼ë©´ ì¼ë°˜ ë‹¨ì–´ë¡œ ì²˜ë¦¬
                words = remaining_text.split()
                if words:
                    for word in words:
                        tokens.append((word, 1.0, word_id))
                        word_id += 1
                break
        
        return tokens
    
    def tokenize_with_weights(self, text: str) -> Dict[str, List]:
        """í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•˜ê³  ê°€ì¤‘ì¹˜ ì •ë³´ í¬í•¨"""
        
        if not self.use_custom_tokenizer:
            # ê¸°ë³¸ í† í¬ë‚˜ì´ì € ì‚¬ìš©
            tokens = self.tokenizer.encode(text, add_special_tokens=True)
            weights = [1.0] * len(tokens)
            word_ids = list(range(len(tokens)))
            return {'tokens': [tokens], 'weights': [weights], 'word_ids': [word_ids]}
        
        # ê³ ê¸‰ ê°€ì¤‘ì¹˜ íŒŒì‹±
        parsed = self.parse_prompt_weights(text)
        
        tokens = []
        weights = []
        word_ids = []
        
        for word, weight, word_id in parsed:
            # ë‹¨ì–´ë¥¼ í† í°ìœ¼ë¡œ ë³€í™˜
            word_tokens = self.tokenizer.encode(word, add_special_tokens=False)
            
            tokens.extend(word_tokens)
            weights.extend([weight] * len(word_tokens))
            word_ids.extend([word_id] * len(word_tokens))
        
        # íŠ¹ìˆ˜ í† í° ì¶”ê°€
        tokens = [self.tokenizer.bos_token_id] + tokens + [self.tokenizer.eos_token_id]
        weights = [1.0] + weights + [1.0]
        word_ids = [0] + word_ids + [0]
        
        return {'tokens': [tokens], 'weights': [weights], 'word_ids': [word_ids]}
    
    def _grouper(self, n, iterable):
        """ì²­í‚¹ í—¬í¼"""
        it = iter(iterable)
        while True:
            chunk = list(itertools.islice(it, n))
            if not chunk:
                return
            yield chunk
    
    def _norm_mag(self, w, n):
        """ê°€ì¤‘ì¹˜ ì •ê·œí™”"""
        d = w - 1
        return 1 + np.sign(d) * np.sqrt(np.abs(d)**2 / n)
    
    def divide_length(self, word_ids, weights):
        """ë‹¨ì–´ ê¸¸ì´ë³„ ê°€ì¤‘ì¹˜ ë¶„ë°°"""
        sums = dict(zip(*np.unique(word_ids, return_counts=True)))
        sums[0] = 1
        weights = [[self._norm_mag(w, sums[id]) if id != 0 else 1.0
                    for w, id in zip(x, y)] for x, y in zip(weights, word_ids)]
        return weights
    
    def from_zero(self, weights, base_emb):
        """ê°€ì¤‘ì¹˜ë¥¼ ì„ë² ë”©ì— ì ìš© (A1111 ë°©ì‹)"""
        weight_tensor = torch.tensor(weights, dtype=base_emb.dtype, device=base_emb.device)
        weight_tensor = weight_tensor.reshape(1, -1, 1).expand(base_emb.shape)
        return base_emb * weight_tensor
    
    def encode_prompt(self, prompt: str, negative_prompt: str = "") -> Tuple[torch.Tensor, torch.Tensor]:
        """í”„ë¡¬í”„íŠ¸ ì¸ì½”ë”© (ë©”ì¸ í•¨ìˆ˜)"""
        
        # ê¸ì • í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬
        pos_tokenized = self.tokenize_with_weights(prompt)
        pos_embeddings = self._encode_tokens(pos_tokenized)
        
        # ë¶€ì • í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬
        if negative_prompt:
            neg_tokenized = self.tokenize_with_weights(negative_prompt)
            neg_embeddings = self._encode_tokens(neg_tokenized)
        else:
            # ë¹ˆ í”„ë¡¬í”„íŠ¸ ì„ë² ë”©
            empty_tokens = self.tokenizer.encode("", add_special_tokens=True)
            empty_input = torch.tensor([empty_tokens], device=self.text_encoder.device)
            with torch.no_grad():
                neg_embeddings = self.text_encoder(empty_input)[0]
        
        return pos_embeddings, neg_embeddings
    
    def _encode_tokens(self, tokenized_data: Dict[str, List]) -> torch.Tensor:
        """í† í°ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        
        tokens = tokenized_data['tokens'][0]
        weights = tokenized_data['weights'][0]
        word_ids = tokenized_data['word_ids'][0]
        
        # í† í° ê¸¸ì´ ì¡°ì • (77í† í° ì œí•œ í•´ì œ)
        max_length = 77  # ê¸°ë³¸ê°’, í•„ìš”ì‹œ í™•ì¥
        if len(tokens) > max_length:
            # ì²­í‚¹ ì²˜ë¦¬
            return self._encode_long_prompt(tokens, weights, word_ids, max_length)
        
        # íŒ¨ë”©
        while len(tokens) < max_length:
            tokens.append(self.tokenizer.pad_token_id or 0)
            weights.append(1.0)
            word_ids.append(0)
        
        # ê¸°ë³¸ ì„ë² ë”© ìƒì„±
        token_tensor = torch.tensor([tokens], device=self.text_encoder.device)
        with torch.no_grad():
            base_embeddings = self.text_encoder(token_tensor)[0]
        
        # ê°€ì¤‘ì¹˜ ì ìš©
        if self.weight_mode == "A1111":
            return self._apply_a1111_weights(base_embeddings, weights, word_ids)
        elif self.weight_mode == "comfy++":
            return self._apply_comfy_weights(base_embeddings, weights, word_ids)
        else:
            return base_embeddings
    
    def _encode_long_prompt(self, tokens: List[int], weights: List[float], word_ids: List[int], chunk_size: int) -> torch.Tensor:
        """ê¸´ í”„ë¡¬í”„íŠ¸ ì²­í‚¹ ì²˜ë¦¬"""
        
        chunks = []
        for i in range(0, len(tokens), chunk_size-2):  # íŠ¹ìˆ˜ í† í° ê³µê°„ í™•ë³´
            chunk_tokens = tokens[i:i+chunk_size-2]
            chunk_weights = weights[i:i+chunk_size-2]
            chunk_word_ids = word_ids[i:i+chunk_size-2]
            
            # íŠ¹ìˆ˜ í† í° ì¶”ê°€
            full_tokens = [self.tokenizer.bos_token_id] + chunk_tokens + [self.tokenizer.eos_token_id]
            full_weights = [1.0] + chunk_weights + [1.0]
            full_word_ids = [0] + chunk_word_ids + [0]
            
            # íŒ¨ë”©
            while len(full_tokens) < chunk_size:
                full_tokens.append(self.tokenizer.pad_token_id or 0)
                full_weights.append(1.0)
                full_word_ids.append(0)
            
            # ì¸ì½”ë”©
            token_tensor = torch.tensor([full_tokens], device=self.text_encoder.device)
            with torch.no_grad():
                chunk_emb = self.text_encoder(token_tensor)[0]
            
            # ê°€ì¤‘ì¹˜ ì ìš©
            if self.weight_mode == "A1111":
                chunk_emb = self._apply_a1111_weights(chunk_emb, full_weights, full_word_ids)
            elif self.weight_mode == "comfy++":
                chunk_emb = self._apply_comfy_weights(chunk_emb, full_weights, full_word_ids)
            
            chunks.append(chunk_emb)
        
        # ì²­í¬ ë³‘í•© (í‰ê· )
        if len(chunks) == 1:
            return chunks[0]
        else:
            return torch.mean(torch.stack(chunks), dim=0)
    
    def _apply_a1111_weights(self, embeddings: torch.Tensor, weights: List[float], word_ids: List[int]) -> torch.Tensor:
        """A1111 ìŠ¤íƒ€ì¼ ê°€ì¤‘ì¹˜ ì ìš©"""
        weighted_emb = self.from_zero([weights], embeddings)
        
        # A1111 ì •ê·œí™”
        norm_base = torch.linalg.norm(embeddings)
        norm_weighted = torch.linalg.norm(weighted_emb)
        
        if norm_weighted > 0:
            embeddings_final = (norm_base / norm_weighted) * weighted_emb
        else:
            embeddings_final = weighted_emb
        
        return embeddings_final
    
    def _apply_comfy_weights(self, embeddings: torch.Tensor, weights: List[float], word_ids: List[int]) -> torch.Tensor:
        """ComfyUI++ ìŠ¤íƒ€ì¼ ê°€ì¤‘ì¹˜ ì ìš© (ê³ ê¸‰)"""
        
        # ê¸¸ì´ë³„ ê°€ì¤‘ì¹˜ ë¶„ë°°
        weights_normalized = self.divide_length([word_ids], [weights])[0]
        
        # ê°€ì¤‘ì¹˜ ì ìš©
        weighted_emb = self.from_zero([weights_normalized], embeddings)
        
        # ë¶„í¬ ë³µì›
        fixed_std = (embeddings.std() / weighted_emb.std()) * (weighted_emb - weighted_emb.mean())
        embeddings_final = fixed_std + (embeddings.mean() - fixed_std.mean())
        
        return embeddings_final
```

### 2. í”„ë¦¬ì…‹ ì‹œìŠ¤í…œ êµ¬í˜„

**íŒŒì¼: src/nicediff/services/preset_manager.py**

```python
import json
import os
from pathlib import Path
from typing import List, Dict, Any

class PresetManager:
    """í”„ë¡¬í”„íŠ¸ í”„ë¦¬ì…‹ ê´€ë¦¬"""
    
    def __init__(self):
        self.preset_dir = Path("models/preset")
        self.pos_dir = self.preset_dir / "pos_prompt"
        self.neg_dir = self.preset_dir / "neg_prompt"
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.pos_dir.mkdir(parents=True, exist_ok=True)
        self.neg_dir.mkdir(parents=True, exist_ok=True)
        
        # ê¸°ë³¸ í”„ë¦¬ì…‹ ìƒì„±
        self._create_default_presets()
    
    def _create_default_presets(self):
        """ê¸°ë³¸ í”„ë¦¬ì…‹ íŒŒì¼ ìƒì„±"""
        
        # ê¸ì • í”„ë¡¬í”„íŠ¸ í”„ë¦¬ì…‹ë“¤
        positive_presets = {
            "Quality": {
                "prompt": "masterpiece, best quality, highly detailed, sharp focus, professional",
                "description": "ê¸°ë³¸ í’ˆì§ˆ í–¥ìƒ íƒœê·¸"
            },
            "Photorealistic": {
                "prompt": "photorealistic, realistic, photo, 8k uhd, high resolution, professional photography",
                "description": "ì‚¬ì‹¤ì ì¸ ì‚¬ì§„ ìŠ¤íƒ€ì¼"
            },
            "Anime": {
                "prompt": "anime style, manga style, illustration, detailed anime art, vibrant colors",
                "description": "ì• ë‹ˆë©”ì´ì…˜ ìŠ¤íƒ€ì¼"
            },
            "Portrait": {
                "prompt": "beautiful face, detailed eyes, detailed skin, perfect anatomy, beautiful lighting",
                "description": "ì¸ë¬¼í™” ì „ìš© íƒœê·¸"
            },
            "Landscape": {
                "prompt": "beautiful landscape, scenic view, natural lighting, atmospheric perspective, depth of field",
                "description": "í’ê²½í™” ì „ìš© íƒœê·¸"
            },
            "Fantasy": {
                "prompt": "fantasy art, magical, mystical, ethereal, enchanting, otherworldly",
                "description": "íŒíƒ€ì§€ ì•„íŠ¸ ìŠ¤íƒ€ì¼"
            },
            "Cinematic": {
                "prompt": "cinematic lighting, dramatic lighting, film grain, movie poster style",
                "description": "ì˜í™”ì  ë¶„ìœ„ê¸°"
            }
        }
        
        # ë¶€ì • í”„ë¡¬í”„íŠ¸ í”„ë¦¬ì…‹ë“¤
        negative_presets = {
            "Basic": {
                "prompt": "worst quality, low quality, normal quality, lowres, bad anatomy, bad hands",
                "description": "ê¸°ë³¸ í’ˆì§ˆ ì œì™¸ íƒœê·¸"
            },
            "People": {
                "prompt": "bad anatomy, bad hands, bad fingers, missing fingers, extra fingers, bad proportions, deformed, ugly face",
                "description": "ì¸ë¬¼ ê·¸ë¦´ ë•Œ ì œì™¸í•  ê²ƒë“¤"
            },
            "Artifacts": {
                "prompt": "blurry, noisy, jpeg artifacts, compression artifacts, oversaturated, duplicate",
                "description": "ì´ë¯¸ì§€ ì•„í‹°íŒ©íŠ¸ ì œê±°"
            },
            "NSFW": {
                "prompt": "nsfw, nude, explicit, sexual content, inappropriate",
                "description": "ì„±ì¸ ì½˜í…ì¸  ì œì™¸"
            },
            "Text": {
                "prompt": "text, watermark, signature, logo, username, artist name, copyright",
                "description": "í…ìŠ¤íŠ¸ ë° ì›Œí„°ë§ˆí¬ ì œê±°"
            },
            "Deformed": {
                "prompt": "deformed, disfigured, mutation, mutated, extra limbs, missing limbs, poorly drawn",
                "description": "ë³€í˜•ëœ í˜•íƒœ ì œì™¸"
            }
        }
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        for name, data in positive_presets.items():
            preset_file = self.pos_dir / f"{name}.json"
            if not preset_file.exists():
                with open(preset_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
        
        for name, data in negative_presets.items():
            preset_file = self.neg_dir / f"{name}.json"
            if not preset_file.exists():
                with open(preset_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
    
    def get_positive_presets(self) -> List[Dict[str, str]]:
        """ê¸ì • í”„ë¡¬í”„íŠ¸ í”„ë¦¬ì…‹ ëª©ë¡ ë°˜í™˜"""
        presets = []
        
        for preset_file in self.pos_dir.glob("*.json"):
            try:
                with open(preset_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    presets.append({
                        'name': preset_file.stem,
                        'prompt': data.get('prompt', ''),
                        'description': data.get('description', '')
                    })
            except Exception as e:
                print(f"í”„ë¦¬ì…‹ ë¡œë“œ ì‹¤íŒ¨ {preset_file}: {e}")
        
        return sorted(presets, key=lambda x: x['name'])
    
    def get_negative_presets(self) -> List[Dict[str, str]]:
        """ë¶€ì • í”„ë¡¬í”„íŠ¸ í”„ë¦¬ì…‹ ëª©ë¡ ë°˜í™˜"""
        presets = []
        
        for preset_file in self.neg_dir.glob("*.json"):
            try:
                with open(preset_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    presets.append({
                        'name': preset_file.stem,
                        'prompt': data.get('prompt', ''),
                        'description': data.get('description', '')
                    })
            except Exception as e:
                print(f"í”„ë¦¬ì…‹ ë¡œë“œ ì‹¤íŒ¨ {preset_file}: {e}")
        
        return sorted(presets, key=lambda x: x['name'])
    
    def add_preset(self, name: str, prompt: str, description: str, is_negative: bool = False):
        """ìƒˆ í”„ë¦¬ì…‹ ì¶”ê°€"""
        preset_data = {
            'prompt': prompt,
            'description': description
        }
        
        target_dir = self.neg_dir if is_negative else self.pos_dir
        preset_file = target_dir / f"{name}.json"
        
        with open(preset_file, 'w', encoding='utf-8') as f:
            json.dump(preset_data, f, ensure_ascii=False, indent=2)
    
    def delete_preset(self, name: str, is_negative: bool = False):
        """í”„ë¦¬ì…‹ ì‚­ì œ"""
        target_dir = self.neg_dir if is_negative else self.pos_dir
        preset_file = target_dir / f"{name}.json"
        
        if preset_file.exists():
            preset_file.unlink()
```

### 3. í”„ë¡¬í”„íŠ¸ íŒ¨ë„ UI ê°œì„ 

**íŒŒì¼: src/nicediff/ui/prompt_panel.py (ìˆ˜ì •)**

```python
# ê¸°ì¡´ importì— ì¶”ê°€
from ..services.preset_manager import PresetManager

class PromptPanel:
    def __init__(self, state_manager):
        self.state = state_manager
        self.preset_manager = PresetManager()
        
        # ê³ ê¸‰ ì¸ì½”ë”© ì„¤ì •
        self.use_custom_tokenizer = True
        self.weight_interpretation = "A1111"  # "A1111" ë˜ëŠ” "comfy++"
    
    def render(self):
        with ui.card().classes('w-full p-4'):
            # ê³ ê¸‰ ì¸ì½”ë”© ì„¤ì • (ìƒë‹¨ì— ì¶”ê°€)
            with ui.expansion('ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ì„¤ì •', icon='settings').classes('w-full mb-4'):
                with ui.row().classes('w-full gap-4 items-center'):
                    # ì»¤ìŠ¤í…€ í† í¬ë‚˜ì´ì € í† ê¸€
                    ui.label('ì»¤ìŠ¤í…€ í† í¬ë‚˜ì´ì €:').classes('min-w-fit')
                    self.custom_tokenizer_switch = ui.switch(
                        value=self.use_custom_tokenizer,
                        on_change=self._on_tokenizer_change
                    ).props('color=blue')
                    
                    # ê°€ì¤‘ì¹˜ í•´ì„ ë°©ì‹ ì„ íƒ
                    ui.label('ê°€ì¤‘ì¹˜ ì²˜ë¦¬:').classes('min-w-fit ml-4')
                    self.weight_mode_select = ui.select(
                        options=['A1111', 'comfy++'],
                        value=self.weight_interpretation,
                        on_change=self._on_weight_mode_change
                    ).classes('min-w-32')
            
            # ê¸ì • í”„ë¡¬í”„íŠ¸
            with ui.column().classes('w-full gap-2'):
                ui.label('ê¸ì • í”„ë¡¬í”„íŠ¸').classes('text-lg font-medium text-green-400')
                
                self.positive_textarea = ui.textarea(
                    placeholder='ê¸ì •ì ì¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”...',
                    value=self.state.get_param('prompt', ''),
                ).props('outlined autogrow').classes('w-full min-h-24').on(
                    'update:model-value', 
                    lambda e: self.state.update_param('prompt', e.args[0])
                )
                
                # ê¸ì • í”„ë¡¬í”„íŠ¸ í”„ë¦¬ì…‹ ë²„íŠ¼ë“¤
                with ui.row().classes('w-full gap-1 flex-wrap'):
                    ui.label('í”„ë¦¬ì…‹:').classes('text-sm text-gray-400 mr-2')
                    for preset in self.preset_manager.get_positive_presets():
                        ui.button(
                            preset['name'],
                            on_click=lambda p=preset: self._add_positive_preset(p)
                        ).props('size=sm color=green outline').tooltip(preset['description'])
            
            # ë¶€ì • í”„ë¡¬í”„íŠ¸  
            with ui.column().classes('w-full gap-2 mt-4'):
                ui.label('ë¶€ì • í”„ë¡¬í”„íŠ¸').classes('text-lg font-medium text-red-400')
                
                self.negative_textarea = ui.textarea(
                    placeholder='ì œì™¸í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”...',
                    value=self.state.get_param('negative_prompt', ''),
                ).props('outlined autogrow').classes('w-full min-h-24').on(
                    'update:model-value',
                    lambda e: self.state.update_param('negative_prompt', e.args[0])
                )
                
                # ë¶€ì • í”„ë¡¬í”„íŠ¸ í”„ë¦¬ì…‹ ë²„íŠ¼ë“¤
                with ui.row().classes('w-full gap-1 flex-wrap'):
                    ui.label('í”„ë¦¬ì…‹:').classes('text-sm text-gray-400 mr-2')
                    for preset in self.preset_manager.get_negative_presets():
                        ui.button(
                            preset['name'],
                            on_click=lambda p=preset: self._add_negative_preset(p)
                        ).props('size=sm color=red outline').tooltip(preset['description'])
    
    def _on_tokenizer_change(self, event):
        """ì»¤ìŠ¤í…€ í† í¬ë‚˜ì´ì € ì„¤ì • ë³€ê²½"""
        self.use_custom_tokenizer = event.args[0]
        self.state.set('use_custom_tokenizer', self.use_custom_tokenizer)
        print(f"âœ… ì»¤ìŠ¤í…€ í† í¬ë‚˜ì´ì €: {'í™œì„±í™”' if self.use_custom_tokenizer else 'ë¹„í™œì„±í™”'}")
    
    def _on_weight_mode_change(self, event):
        """ê°€ì¤‘ì¹˜ í•´ì„ ë°©ì‹ ë³€ê²½"""
        self.weight_interpretation = event.args[0]
        self.state.set('weight_interpretation', self.weight_interpretation)
        print(f"âœ… ê°€ì¤‘ì¹˜ ì²˜ë¦¬ ë°©ì‹: {self.weight_interpretation}")
    
    def _add_positive_preset(self, preset):
        """ê¸ì • í”„ë¡¬í”„íŠ¸ í”„ë¦¬ì…‹ ì¶”ê°€"""
        current_prompt = self.positive_textarea.value or ''
        
        if current_prompt and not current_prompt.endswith(', '):
            new_prompt = current_prompt + ', ' + preset['prompt']
        else:
            new_prompt = current_prompt + preset['prompt']
        
        self.positive_textarea.set_value(new_prompt)
        self.state.update_param('prompt', new_prompt)
        
        ui.notify(f"í”„ë¦¬ì…‹ '{preset['name']}' ì¶”ê°€ë¨", type='positive')
    
    def _add_negative_preset(self, preset):
        """ë¶€ì • í”„ë¡¬í”„íŠ¸ í”„ë¦¬ì…‹ ì¶”ê°€"""
        current_prompt = self.negative_textarea.value or ''
        
        if current_prompt and not current_prompt.endswith(', '):
            new_prompt = current_prompt + ', ' + preset['prompt']
        else:
            new_prompt = current_prompt + preset['prompt']
        
        self.negative_textarea.set_value(new_prompt)
        self.state.update_param('negative_prompt', new_prompt)
        
        ui.notify(f"ë¶€ì • í”„ë¦¬ì…‹ '{preset['name']}' ì¶”ê°€ë¨", type='positive')
```

### 4. ìƒì„± ëª¨ë“œ í†µí•©

**íŒŒì¼: src/nicediff/domains/generation/modes/txt2img.py (ìˆ˜ì •)**

```python
# ê¸°ì¡´ importì— ì¶”ê°€
from ..services.advanced_encoder import AdvancedTextEncoder

class Txt2ImgMode:
    def __init__(self, pipeline: Any, device: str):
        self.pipeline = pipeline
        self.device = device
    
    async def generate(self, params: Txt2ImgParams) -> List[Any]:
        """í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„± (ê³ ê¸‰ ì¸ì½”ë”© ì ìš©)"""
        print(f"ğŸ¨ Txt2Img ìƒì„± ì‹œì‘ - Seed: {params.seed}")
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì ìš©
        SchedulerManager.apply_scheduler_to_pipeline(
            self.pipeline, 
            params.sampler, 
            params.scheduler
        )
        
        # CLIP Skip ì ìš©
        if params.clip_skip > 1:
            SchedulerManager.apply_clip_skip_to_pipeline(
                self.pipeline, 
                params.clip_skip
            )
        
        # ê³ ê¸‰ í…ìŠ¤íŠ¸ ì¸ì½”ë” ì‚¬ìš©
        use_custom = getattr(params, 'use_custom_tokenizer', True)
        weight_mode = getattr(params, 'weight_interpretation', 'A1111')
        
        encoder = AdvancedTextEncoder(
            self.pipeline, 
            weight_mode=weight_mode,
            use_custom_tokenizer=use_custom
        )
        
        # í”„ë¡¬í”„íŠ¸ ì¸ì½”ë”© (77í† í° ì œí•œ ì—†ìŒ)
        print(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ì¸ì½”ë”© - ëª¨ë“œ: {weight_mode}, ì»¤ìŠ¤í…€: {use_custom}")
        prompt_embeds, negative_prompt_embeds = encoder.encode_prompt(
            params.prompt, 
            params.negative_prompt
        )
        
        print(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ:")
        print(f"   - ê¸ì •: {prompt_embeds.shape}")
        print(f"   - ë¶€ì •: {negative_prompt_embeds.shape}")
        
        def _generate():
            """ì‹¤ì œ ìƒì„± ë¡œì§"""
            generator = torch.Generator(device=self.device)
            if params.seed > 0:
                generator.manual_seed(params.seed)
            
            try:
                # ì„ë² ë”©ì„ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ìƒì„±
                result = self.pipeline(
                    prompt_embeds=prompt_embeds,
                    negative_prompt_embeds=negative_prompt_embeds,
                    height=params.height,
                    width=params.width,
                    num_inference_steps=params.steps,
                    guidance_scale=params.cfg_scale,
                    generator=generator,
                    num_images_per_prompt=params.batch_size,
                    output_type='pil'
                )
                
                return result.images if hasattr(result, 'images') else result
                
            except Exception as e:
                print(f"âŒ íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                return []
        
        # ìƒì„± ì‹¤í–‰
        generated_images = await asyncio.to_thread(_generate)
        
        print(f"âœ… ìƒì„± ì™„ë£Œ: {len(generated_images)}ê°œ ì´ë¯¸ì§€")
        return generated_images
```

**íŒŒì¼: src/nicediff/domains/generation/modes/img2img.py (ìˆ˜ì •)**

```python
# txt2img.pyì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ê³ ê¸‰ ì¸ì½”ë” ì ìš©

class Img2ImgMode:
    async def generate(self, params: Img2ImgParams) -> List[Any]:
        # ê¸°ì¡´ ì½”ë“œ ìœ ì§€í•˜ë˜ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ë¶€ë¶„ë§Œ êµì²´
        
        # ê³ ê¸‰ í…ìŠ¤íŠ¸ ì¸ì½”ë” ì‚¬ìš©
        use_custom = getattr(params, 'use_custom_tokenizer', True)
        weight_mode = getattr(params, 'weight_interpretation', 'A1111')
        
        encoder = AdvancedTextEncoder(
            self.pipeline, 
            weight_mode=weight_mode,
            use_custom_tokenizer=use_custom
        )
        
        prompt_embeds, negative_prompt_embeds = encoder.encode_prompt(
            params.prompt, 
            params.negative_prompt
        )
        
        # ë‚˜ë¨¸ì§€ img2img ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼í•˜ë˜
        # íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ ì‹œ prompt_embeds ì‚¬ìš©
```

### 5. ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸

**íŒŒì¼: config.toml (ì¶”ê°€)**

```toml
[advanced_encoding]
# ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ì¸ì½”ë”© ì„¤ì •
use_custom_tokenizer = true
weight_interpretation = "A1111"  # "A1111" ë˜ëŠ” "comfy++"
enable_long_prompts = true
max_chunk_size = 77

[presets]
# í”„ë¦¬ì…‹ ì‹œìŠ¤í…œ ì„¤ì •
auto_create_defaults = true
preset_directory = "models/preset"
```

## ğŸš« ì œê±°í•  ê¸°ëŠ¥

### 1. ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ìµœì í™” ë²„íŠ¼ ì œê±°

**íŒŒì¼: prompt_panel.pyì—ì„œ ì œê±°í•  ë¶€ë¶„**

```python
# ì œê±°í•  ì½”ë“œë“¤:
# - "í”„ë¡¬í”„íŠ¸ ìµœì í™”" ë²„íŠ¼
# - "ê¸´ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬" ë²„íŠ¼  
# - ê´€ë ¨ëœ ëª¨ë“  ìµœì í™” í•¨ìˆ˜ë“¤
```

### 2. ê¸°ì¡´ í† í° ì œí•œ ë¡œì§ ì œê±°

**íŒŒì¼: txt2img.py, img2img.pyì—ì„œ ì œê±°**

```python
# ì œê±°í•  ì½”ë“œë“¤:
# - _truncate_prompt_with_tokenizer() í•¨ìˆ˜
# - 77í† í° ì œí•œ ì²´í¬
# - í”„ë¡¬í”„íŠ¸ ì˜ë¦¼ ê²½ê³  ë©”ì‹œì§€
```

## ğŸ“‹ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### êµ¬í˜„ ìˆœì„œ
1. [ ] AdvancedTextEncoder í´ë˜ìŠ¤ êµ¬í˜„
2. [ ] PresetManager í´ë˜ìŠ¤ êµ¬í˜„  
3. [ ] ê¸°ë³¸ í”„ë¦¬ì…‹ JSON íŒŒì¼ ìƒì„±
4. [ ] prompt_panel.py UI ì—…ë°ì´íŠ¸
5. [ ] txt2img.py, img2img.py ì¸ì½”ë” í†µí•©
6. [ ] ê¸°ì¡´ ìµœì í™” ë²„íŠ¼ ì œê±°
7. [ ] config.toml ì„¤ì • ì¶”ê°€

### í…ŒìŠ¤íŠ¸ í•­ëª©
- [ ] ê¸°ì¡´ ì§§ì€ í”„ë¡¬í”„íŠ¸ ë™ì¼í•œ ê²°ê³¼
- [ ] ê¸´ í”„ë¡¬í”„íŠ¸ ì •ìƒ ì²˜ë¦¬ (77í† í° ì´ˆê³¼)
- [ ] ê°€ì¤‘ì¹˜ ë¬¸ë²• ì ìš© í™•ì¸: (word:1.2), ((word)), [word]
- [ ] A1111ê³¼ comfy++ ëª¨ë“œ ì°¨ì´ í™•ì¸
- [ ] í”„ë¦¬ì…‹ ë²„íŠ¼ ë™ì‘ í™•ì¸
- [ ] í”„ë¦¬ì…‹ ì¶”ê°€/ì´ì–´ì“°ê¸° ê¸°ëŠ¥
- [ ] UI ì„¤ì • ì €ì¥/ë³µì›

### ìµœì¢… ê²°ê³¼
âœ… **77í† í° ì œí•œ ì™„ì „ í•´ì œ**  
âœ… **ê³ ê¸‰ ê°€ì¤‘ì¹˜ ì²˜ë¦¬ (A1111/ComfyUI ë°©ì‹)**  
âœ… **í¸ë¦¬í•œ í”„ë¦¬ì…‹ ì‹œìŠ¤í…œ**  
âœ… **ê¸°ì¡´ UI/ê¸°ëŠ¥ 100% í˜¸í™˜**  
âœ… **ê¸´ í”„ë¡¬í”„íŠ¸ ìë™ ì²­í‚¹**  
âœ… **ì„¤ì • ê°„í¸í™” (2ê°œ í† ê¸€ë§Œ)**

## ğŸ¯ ìµœì¢… ì‚¬ìš©ì ê²½í—˜

1. **ì„¤ì •**: í”„ë¡¬í”„íŠ¸ íŒ¨ë„ì—ì„œ ê°„ë‹¨í•œ í† ê¸€ 2ê°œë§Œ ì„¤ì •
2. **ì…ë ¥**: ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ í”„ë¡¬í”„íŠ¸ ì…ë ¥ (ê¸¸ì´ ì œí•œ ì—†ìŒ)
3. **í”„ë¦¬ì…‹**: ì›í´ë¦­ìœ¼ë¡œ í’ˆì§ˆ/ìŠ¤íƒ€ì¼ íƒœê·¸ ì¶”ê°€
4. **ê²°ê³¼**: ë” ì •í™•í•œ ê°€ì¤‘ì¹˜ ì ìš©ê³¼ ê¸´ í”„ë¡¬í”„íŠ¸ ì§€ì›

**ì‚¬ìš©ìëŠ” ì„¤ì • í•œ ë²ˆë§Œ í•˜ë©´ ëª¨ë“  í˜œíƒì„ ìë™ìœ¼ë¡œ ëˆ„ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤!**
