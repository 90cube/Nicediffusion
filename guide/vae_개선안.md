# VAE ì²˜ë¦¬ ìµœì í™” ì§€ì¹¨

## ğŸ¯ ëª©í‘œ
**ë³µì¡í•œ VAE ì²˜ë¦¬ ë¡œì§ì„ ë‹¨ìˆœí™”í•˜ì—¬ ì„±ëŠ¥ê³¼ ì•ˆì •ì„±ì„ ê°œì„ **

## ğŸ“‹ ì‘ì—… ì§€ì¹¨

### 1. **ì¦‰ì‹œ ìˆ˜ì • (1ìˆœìœ„)**
```python
# src/nicediff/domains/generation/modes/img2img.py
# _encode_image() í•¨ìˆ˜ 80ì¤„ â†’ 15ì¤„ë¡œ ë‹¨ìˆœí™”

def _encode_image(self, image: Image.Image) -> torch.Tensor:
    """VAE ì¸ì½”ë”© (ë‹¨ìˆœí™” ë²„ì „)"""
    # RGB ë³€í™˜
    if image.mode != 'RGB':
        image = image.convert('RGB')
    
    # ë‹¨ì¼ ì „ì²˜ë¦¬ ë°©ë²•ë§Œ ì‚¬ìš© (ì„±ê³µë¥  95%)
    import torchvision.transforms as T
    transform = T.Compose([
        T.ToTensor(),
        T.Normalize([0.5], [0.5])
    ])
    
    with torch.no_grad():
        tensor = transform(image).unsqueeze(0)
        tensor = tensor.to(self.device, dtype=self.pipeline.vae.dtype)
        
        # VAE ì¸ì½”ë”©
        latent = self.pipeline.vae.encode(tensor).latent_dist.sample()
        latent *= self.pipeline.vae.config.scaling_factor
        
    return latent

# ì œê±°í•  ê²ƒë“¤:
# - ëª¨ë“  print ë””ë²„ê¹… ì½”ë“œ (80% ë¶„ëŸ‰)
# - 3ê°€ì§€ ì „ì²˜ë¦¬ ì‹œë„ ë¡œì§ 
# - ë³µì¡í•œ fallback ì²˜ë¦¬
# - ìƒì„¸í•œ ê²€ì¦ ë¡œì§
```

### 2. **í”„ë¦¬ë·° ì²˜ë¦¬ ê°œì„  (2ìˆœìœ„)**
```python
# ì´ë¯¸ì§€ ì—…ë¡œë“œ ì²˜ë¦¬ ë‹¨ìˆœí™”
def handle_image_upload(self, upload_event):
    """ì—…ë¡œë“œ ì´ë¯¸ì§€ ì²˜ë¦¬ (ë¦¬ì‚¬ì´ì¦ˆ ê¸ˆì§€)"""
    
    # PIL ì´ë¯¸ì§€ ë³€í™˜ë§Œ
    image = Image.open(io.BytesIO(upload_event.content))
    
    # ìƒíƒœ ì €ì¥ (ì›ë³¸ ê·¸ëŒ€ë¡œ)
    self.state.set('init_image', image)
    
    # í”„ë¦¬ë·° í‘œì‹œ (CSS ë°˜ì‘í˜•)
    self.update_preview_display(image)

# ì œê±°í•  ê²ƒë“¤:
# - ëª¨ë“  thumbnail(), resize() í˜¸ì¶œ
# - ë¶ˆí•„ìš”í•œ ì´ë¯¸ì§€ ë³µì‚¬
# - í”„ë¦¬ë·°ìš© ë©”ëª¨ë¦¬ í• ë‹¹
```

### 3. **VAE ë¡œë”© ë‹¨ìˆœí™” (3ìˆœìœ„)**
```python
# state_manager.pyì˜ VAE ë¡œë”© ë¡œì§ ë‹¨ìˆœí™”
async def load_vae(self, vae_path: str):
    """VAE ë¡œë“œ (ë‹¨ìˆœí™”)"""
    try:
        vae_model = AutoencoderKL.from_pretrained(vae_path, torch_dtype=torch.float16)
        self.pipeline.vae = vae_model.to(self.device)
        self.set('current_vae_path', vae_path)
        return True
    except Exception as e:
        print(f"VAE ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

# ì œê±°í•  ê²ƒë“¤:
# - ë³µì¡í•œ ì—ëŸ¬ ì²˜ë¦¬
# - ê³¼ë„í•œ ë¡œê·¸ ì¶œë ¥
# - ë¶ˆí•„ìš”í•œ ê²€ì¦ ë¡œì§
```

## ğŸš« í•˜ì§€ ë§ ê²ƒ

1. **ìƒˆë¡œìš´ ëª¨ë“ˆ ìƒì„± ê¸ˆì§€** - ê¸°ì¡´ ì½”ë“œ ìˆ˜ì •ë§Œ
2. **ì•„í‚¤í…ì²˜ ë³€ê²½ ê¸ˆì§€** - ì„±ëŠ¥ ìš°ì„ 
3. **ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸ˆì§€** - ì˜ì¡´ì„± ì¦ê°€ ë°©ì§€
4. **í”„ë¦¬ë·° ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ê¸ˆì§€** - CSSê°€ ì²˜ë¦¬
5. **ë””ë²„ê¹… ì½”ë“œ ì¶”ê°€ ê¸ˆì§€** - ê¸°ì¡´ ê²ƒë„ ëª¨ë‘ ì œê±°

## âœ… ì„±ëŠ¥ ëª©í‘œ

- **ì²˜ë¦¬ì‹œê°„**: VAE ì¸ì½”ë”© 1-2ì´ˆ â†’ 0.3ì´ˆ
- **ë©”ëª¨ë¦¬**: ë¶ˆí•„ìš”í•œ ë³µì‚¬ ì œê±°ë¡œ -500MB
- **ì½”ë“œëŸ‰**: 80ì¤„ â†’ 15ì¤„ë¡œ ë‹¨ìˆœí™”
- **ì•ˆì •ì„±**: ì—ëŸ¬ ì¼€ì´ìŠ¤ 90% ê°ì†Œ

## ğŸ”§ ê²€ì¦ ë°©ë²•

```python
# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì½”ë“œ
import time
start_time = time.time()
latent = self._encode_image(test_image)
end_time = time.time()
print(f"VAE ì¸ì½”ë”© ì‹œê°„: {end_time - start_time:.3f}ì´ˆ")

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
import psutil
process = psutil.Process()
memory_usage = process.memory_info().rss / 1024 / 1024  # MB
print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_usage:.1f}MB")
```

## ğŸ“ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] `_encode_image()` í•¨ìˆ˜ 80ì¤„ â†’ 15ì¤„ ë‹¨ìˆœí™”
- [ ] ëª¨ë“  ë””ë²„ê¹… printë¬¸ ì œê±°
- [ ] 3ê°€ì§€ ì „ì²˜ë¦¬ ì‹œë„ ë¡œì§ ì œê±° 
- [ ] í”„ë¦¬ë·° ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ë¡œì§ ì œê±°
- [ ] VAE ë¡œë”© ë¡œì§ ë‹¨ìˆœí™”
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸

**í•µì‹¬: ë³µì¡í•œ ê²ƒì„ ë‹¨ìˆœí•˜ê²Œ, ì•ˆì •ì ìœ¼ë¡œ, ë¹ ë¥´ê²Œ!**
